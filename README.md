# Introduction to Machine Learning

This repo serves two function: both as my notes and a guide for others.  I will be working through [_Introduction to Statistical Learning with Applications in Python_](https://www.statlearning.com/) and _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ and including some other supplemental resources.

Note that ISLP is freely available from the book's authors and there are lectures freely available that outline most of the material.  
* [Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ)
* [Lab Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rNHU1-iPeDRH-J0cL-CrIda)
* [Lab Jupyter Notebooks](https://github.com/intro-stat-learning/ISLP_labs/tree/stable)
* [Lecture Slides and other resources](https://www.statlearning.com/resources-python)


Additionally, if you find it a better format or want to work through only ISLP and not include any supplemental information, their course is available for free to audit on [edX](https://www.edx.org/learn/python/stanford-university-statistical-learning-with-python)

This "course" will be divided up into modules, not weeks.  Why?  People of different skill levels and backgrounds will need to spend different amounts of time to understand the material.  Further, due to life responsibilities, not everyone can allocate the same number of hours each work to studying.  So remember, it's better to be slow and steady than to give up after a week!

| Module | Topic                                    | ISLP Reading | HoML Reading | Assignment |
|--------|------------------------------------------|--------------|--------------|------------|
| 1      | [Foundations](module1_foundations/00_mod1_foundations_overview.md)                              | [Ch. 1 -2](module1_foundations/ISLP_ch2_notes.pdf)     | Ch 1         |            |
| 2      | [Linear Regression](module2_linear_regression/00_mod2_linear_regression_overview.md)                        | [Ch. 3](module2_linear_regression/ISLP_ch3_notes.pdf)        | Ch 4.1       |            |
| 3      | Classification                           | Ch. 4        | Ch. 3        |            |
| 4      | Resampling and Model Evaluation          | Ch. 5        | Ch. 2        |            |
| 5      | Feature Selection                        | Ch. 6.1, 6.2 |              |            |
| 6      | Regularization                           | Ch 6.3 - 6.6 |              |            |
| 7      | Splines                                  | Ch 7.4, 7.5  |              |            |
| 8      | Trees                                    | Ch. 8.1      | Ch. 6        |            |
| 9      | Ensemble Learning                        | Ch. 8.2      | Ch. 7        |            |
| 10     | Support Vector Machines                  | Ch. 9        | Ch 5         |            |
| 11     | Begin Project                            |              |              |            |
| 12     | Dimensionality Reduction?  Unsupervised? |              |              |            |
| 13     | Intro to Neural Networks                 |              |              |            |

# Chapter Summaries and Notes
Sometimes I will add my own thoughts or something from an outside source to the notes.
I will attempt to mark these by using a colored block.  That said, I make no guarantees that everything is marked nor that everything in a box is not from the book.

# "Pre-Requisites"


# Other sets of notes or exercise solutions
* [https://isl.study.foletta.org/](https://isl.study.foletta.org/)
* [https://tdg5.github.io/stats-learning-notes/](https://tdg5.github.io/stats-learning-notes/)
* [https://blog.princehonest.com/stat-learning/](https://blog.princehonest.com/stat-learning/)